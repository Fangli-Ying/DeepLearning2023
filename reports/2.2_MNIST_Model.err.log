Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\lib\site-packages\jupyter_cache\executors\utils.py", line 64, in single_nb_execution
    **kwargs,
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "D:\ProgramData\Anaconda3\lib\asyncio\base_events.py", line 587, in run_until_complete
    return future.result()
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 664, in async_execute
    cell, index, execution_count=self.code_cells_executed + 1
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms


#2. è¶…å‚æ•°è®¾å®šï¼ˆHyperparameter Tuningï¼‰ï¼šä»£ç ä¸­çš„è¶…å‚æ•°åŒ…æ‹¬input_sizeï¼ˆè¾“å…¥ç‰¹å¾çš„å¤§å°ï¼‰ã€num_classesï¼ˆç±»åˆ«æ•°é‡ï¼‰ã€
#num_epochsï¼ˆè®­ç»ƒè½®æ•°ï¼‰ã€batch_sizeï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰å’Œlearning_rateï¼ˆå­¦ä¹ ç‡ï¼‰ã€‚
#è¿™äº›è¶…å‚æ•°çš„é€‰æ‹©å¯¹äºæ¨¡å‹çš„æ€§èƒ½å’Œè®­ç»ƒè¿‡ç¨‹è‡³å…³é‡è¦ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´å®ƒä»¬æ¥ä¼˜åŒ–æ¨¡å‹çš„è¡¨ç°ã€‚

# Hyper-parameters 
input_size = 28 * 28    # 784
num_classes = 10
num_epochs = 5
batch_size = 100
learning_rate = 0.001

#1. æ•°æ®è¯»å–ï¼ˆData Loadingï¼‰ï¼šåœ¨è¿™æ®µä»£ç ä¸­ï¼Œä½¿ç”¨äº†torchvision.datasets.MNISTæ¥åŠ è½½MNISTæ•°æ®é›†ï¼Œ
#å¹¶é€šè¿‡torch.utils.data.DataLoaderåˆ›å»ºäº†è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ•°æ®åŠ è½½å™¨ã€‚è¿™æ ·å¯ä»¥æ–¹ä¾¿åœ°å¯¹æ•°æ®è¿›è¡Œæ‰¹å¤„ç†å’Œéšæœºæ‰“ä¹±ã€‚

# MNIST dataset (images and labels)
train_dataset = torchvision.datasets.MNIST(root='../../data', 
                                           train=True, 
                                           transform=transforms.ToTensor(),
                                           download=True)

test_dataset = torchvision.datasets.MNIST(root='../../data', 
                                          train=False, 
                                          transform=transforms.ToTensor())

# Data loader (input pipeline)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)





#3. è¿™æ®µä»£ç ä¸­ä½¿ç”¨äº†nn.Linearå®šä¹‰äº†ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹ï¼Œ
#è¾“å…¥å¤§å°ä¸ºinput_sizeï¼Œè¾“å‡ºå¤§å°ä¸ºnum_classesã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥å±‚æ¨¡å‹ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥æ ¹æ®ä»»åŠ¡éœ€æ±‚è®¾è®¡æ›´åŠ å¤æ‚çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

# Logistic regression model
model1 = nn.Linear(input_size, num_classes)

#4. æ¨¡å‹è®­ç»ƒï¼ˆModel Trainingï¼‰ï¼šé€šè¿‡è¿­ä»£è®­ç»ƒæ•°æ®é›†ä¸­çš„æ‰¹æ¬¡ï¼Œå°†è¾“å…¥æ•°æ®ä¼ é€’ç»™æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè®¡ç®—æŸå¤±å¹¶è¿›è¡Œåå‘ä¼ æ’­æ›´æ–°æ¨¡å‹å‚æ•°ã€‚
#ä¼˜åŒ–å™¨ï¼ˆtorch.optim.SGDï¼‰æ ¹æ®è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦æ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼ˆnn.CrossEntropyLossï¼‰ã€‚

# Loss and optimizer
# nn.CrossEntropyLoss() computes softmax internally
criterion = nn.CrossEntropyLoss()  

optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate)  

# Train the model
total_step = len(train_loader)
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # Reshape images to (batch_size, input_size)
        images = images.reshape(-1, input_size)
        
        # Forward pass
        outputs = model1(images)
        loss = criterion(outputs, labels)
        
        
        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
#æ¨¡å‹æµ‹è¯•ï¼ˆModel Testingï¼‰ï¼šåœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¨¡å‹å¯¹æµ‹è¯•é›†ä¸­çš„æ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—å‡†ç¡®ç‡æ¥è¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ã€‚
#é€šè¿‡torch.no_grad()ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¯ä»¥å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œä»¥èŠ‚çœå†…å­˜èµ„æºã€‚
# Test the model
# In test phase, we don't need to compute gradients (for memory efficiency)
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.reshape(-1, input_size)
        outputs = model1(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum()

    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))

# Save the model checkpoint
torch.save(model1.state_dict(), 'model1.ckpt')
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mPermissionError[0m                           Traceback (most recent call last)
[1;32m<ipython-input-1-7bd8c2a1c68c>[0m in [0;36m<module>[1;34m[0m
[0;32m     23[0m                                            [0mtrain[0m[1;33m=[0m[1;32mTrue[0m[1;33m,[0m[1;33m[0m[1;33m[0m[0m
[0;32m     24[0m                                            [0mtransform[0m[1;33m=[0m[0mtransforms[0m[1;33m.[0m[0mToTensor[0m[1;33m([0m[1;33m)[0m[1;33m,[0m[1;33m[0m[1;33m[0m[0m
[1;32m---> 25[1;33m                                            download=True)
[0m[0;32m     26[0m [1;33m[0m[0m
[0;32m     27[0m test_dataset = torchvision.datasets.MNIST(root='../../data', 

[1;32mD:\ProgramData\Anaconda3\lib\site-packages\torchvision\datasets\mnist.py[0m in [0;36m__init__[1;34m(self, root, train, transform, target_transform, download)[0m
[0;32m     85[0m [1;33m[0m[0m
[0;32m     86[0m         [1;32mif[0m [0mdownload[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m---> 87[1;33m             [0mself[0m[1;33m.[0m[0mdownload[0m[1;33m([0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m     88[0m [1;33m[0m[0m
[0;32m     89[0m         [1;32mif[0m [1;32mnot[0m [0mself[0m[1;33m.[0m[0m_check_exists[0m[1;33m([0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\site-packages\torchvision\datasets\mnist.py[0m in [0;36mdownload[1;34m(self)[0m
[0;32m    166[0m             [1;32mreturn[0m[1;33m[0m[1;33m[0m[0m
[0;32m    167[0m [1;33m[0m[0m
[1;32m--> 168[1;33m         [0mos[0m[1;33m.[0m[0mmakedirs[0m[1;33m([0m[0mself[0m[1;33m.[0m[0mraw_folder[0m[1;33m,[0m [0mexist_ok[0m[1;33m=[0m[1;32mTrue[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    169[0m [1;33m[0m[0m
[0;32m    170[0m         [1;31m# download files[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\os.py[0m in [0;36mmakedirs[1;34m(name, mode, exist_ok)[0m
[0;32m    211[0m     [1;32mif[0m [0mhead[0m [1;32mand[0m [0mtail[0m [1;32mand[0m [1;32mnot[0m [0mpath[0m[1;33m.[0m[0mexists[0m[1;33m([0m[0mhead[0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    212[0m         [1;32mtry[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 213[1;33m             [0mmakedirs[0m[1;33m([0m[0mhead[0m[1;33m,[0m [0mexist_ok[0m[1;33m=[0m[0mexist_ok[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    214[0m         [1;32mexcept[0m [0mFileExistsError[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    215[0m             [1;31m# Defeats race condition when another thread created the path[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\os.py[0m in [0;36mmakedirs[1;34m(name, mode, exist_ok)[0m
[0;32m    211[0m     [1;32mif[0m [0mhead[0m [1;32mand[0m [0mtail[0m [1;32mand[0m [1;32mnot[0m [0mpath[0m[1;33m.[0m[0mexists[0m[1;33m([0m[0mhead[0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    212[0m         [1;32mtry[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 213[1;33m             [0mmakedirs[0m[1;33m([0m[0mhead[0m[1;33m,[0m [0mexist_ok[0m[1;33m=[0m[0mexist_ok[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    214[0m         [1;32mexcept[0m [0mFileExistsError[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    215[0m             [1;31m# Defeats race condition when another thread created the path[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\os.py[0m in [0;36mmakedirs[1;34m(name, mode, exist_ok)[0m
[0;32m    221[0m             [1;32mreturn[0m[1;33m[0m[1;33m[0m[0m
[0;32m    222[0m     [1;32mtry[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 223[1;33m         [0mmkdir[0m[1;33m([0m[0mname[0m[1;33m,[0m [0mmode[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    224[0m     [1;32mexcept[0m [0mOSError[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    225[0m         [1;31m# Cannot rely on checking for EEXIST, since the operating system[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;31mPermissionError[0m: [WinError 5] æ‹’ç»è®¿é—®ã€‚: '../../data'
PermissionError: [WinError 5] æ‹’ç»è®¿é—®ã€‚: '../../data'

