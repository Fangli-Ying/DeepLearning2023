Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\lib\site-packages\jupyter_cache\executors\utils.py", line 64, in single_nb_execution
    **kwargs,
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "D:\ProgramData\Anaconda3\lib\asyncio\base_events.py", line 587, in run_until_complete
    return future.result()
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 664, in async_execute
    cell, index, execution_count=self.code_cells_executed + 1
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\msipc\AppData\Roaming\Python\Python37\site-packages\nbclient\client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms


#2. 超参数设定（Hyperparameter Tuning）：代码中的超参数包括input_size（输入特征的大小）、num_classes（类别数量）、
#num_epochs（训练轮数）、batch_size（批次大小）和learning_rate（学习率）。
#这些超参数的选择对于模型的性能和训练过程至关重要，可以通过调整它们来优化模型的表现。

# Hyper-parameters 
input_size = 28 * 28    # 784
num_classes = 10
num_epochs = 5
batch_size = 100
learning_rate = 0.001

#1. 数据读取（Data Loading）：在这段代码中，使用了torchvision.datasets.MNIST来加载MNIST数据集，
#并通过torch.utils.data.DataLoader创建了训练集和测试集的数据加载器。这样可以方便地对数据进行批处理和随机打乱。

# MNIST dataset (images and labels)
train_dataset = torchvision.datasets.MNIST(root='../../data', 
                                           train=True, 
                                           transform=transforms.ToTensor(),
                                           download=True)

test_dataset = torchvision.datasets.MNIST(root='../../data', 
                                          train=False, 
                                          transform=transforms.ToTensor())

# Data loader (input pipeline)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)





#3. 这段代码中使用了nn.Linear定义了一个简单的线性回归模型，
#输入大小为input_size，输出大小为num_classes。这是一个简单的全连接层模型，但在实际应用中，可以根据任务需求设计更加复杂的深度学习模型。

# Logistic regression model
model1 = nn.Linear(input_size, num_classes)

#4. 模型训练（Model Training）：通过迭代训练数据集中的批次，将输入数据传递给模型进行前向传播，计算损失并进行反向传播更新模型参数。
#优化器（torch.optim.SGD）根据计算得到的梯度来更新模型参数，以最小化损失函数（nn.CrossEntropyLoss）。

# Loss and optimizer
# nn.CrossEntropyLoss() computes softmax internally
criterion = nn.CrossEntropyLoss()  

optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate)  

# Train the model
total_step = len(train_loader)
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # Reshape images to (batch_size, input_size)
        images = images.reshape(-1, input_size)
        
        # Forward pass
        outputs = model1(images)
        loss = criterion(outputs, labels)
        
        
        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
#模型测试（Model Testing）：在测试阶段，模型对测试集中的样本进行预测，并计算准确率来评估模型在测试集上的性能。
#通过torch.no_grad()上下文管理器，可以关闭梯度计算，以节省内存资源。
# Test the model
# In test phase, we don't need to compute gradients (for memory efficiency)
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.reshape(-1, input_size)
        outputs = model1(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum()

    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))

# Save the model checkpoint
torch.save(model1.state_dict(), 'model1.ckpt')
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mPermissionError[0m                           Traceback (most recent call last)
[1;32m<ipython-input-1-7bd8c2a1c68c>[0m in [0;36m<module>[1;34m[0m
[0;32m     23[0m                                            [0mtrain[0m[1;33m=[0m[1;32mTrue[0m[1;33m,[0m[1;33m[0m[1;33m[0m[0m
[0;32m     24[0m                                            [0mtransform[0m[1;33m=[0m[0mtransforms[0m[1;33m.[0m[0mToTensor[0m[1;33m([0m[1;33m)[0m[1;33m,[0m[1;33m[0m[1;33m[0m[0m
[1;32m---> 25[1;33m                                            download=True)
[0m[0;32m     26[0m [1;33m[0m[0m
[0;32m     27[0m test_dataset = torchvision.datasets.MNIST(root='../../data', 

[1;32mD:\ProgramData\Anaconda3\lib\site-packages\torchvision\datasets\mnist.py[0m in [0;36m__init__[1;34m(self, root, train, transform, target_transform, download)[0m
[0;32m     85[0m [1;33m[0m[0m
[0;32m     86[0m         [1;32mif[0m [0mdownload[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m---> 87[1;33m             [0mself[0m[1;33m.[0m[0mdownload[0m[1;33m([0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m     88[0m [1;33m[0m[0m
[0;32m     89[0m         [1;32mif[0m [1;32mnot[0m [0mself[0m[1;33m.[0m[0m_check_exists[0m[1;33m([0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\site-packages\torchvision\datasets\mnist.py[0m in [0;36mdownload[1;34m(self)[0m
[0;32m    166[0m             [1;32mreturn[0m[1;33m[0m[1;33m[0m[0m
[0;32m    167[0m [1;33m[0m[0m
[1;32m--> 168[1;33m         [0mos[0m[1;33m.[0m[0mmakedirs[0m[1;33m([0m[0mself[0m[1;33m.[0m[0mraw_folder[0m[1;33m,[0m [0mexist_ok[0m[1;33m=[0m[1;32mTrue[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    169[0m [1;33m[0m[0m
[0;32m    170[0m         [1;31m# download files[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\os.py[0m in [0;36mmakedirs[1;34m(name, mode, exist_ok)[0m
[0;32m    211[0m     [1;32mif[0m [0mhead[0m [1;32mand[0m [0mtail[0m [1;32mand[0m [1;32mnot[0m [0mpath[0m[1;33m.[0m[0mexists[0m[1;33m([0m[0mhead[0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    212[0m         [1;32mtry[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 213[1;33m             [0mmakedirs[0m[1;33m([0m[0mhead[0m[1;33m,[0m [0mexist_ok[0m[1;33m=[0m[0mexist_ok[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    214[0m         [1;32mexcept[0m [0mFileExistsError[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    215[0m             [1;31m# Defeats race condition when another thread created the path[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\os.py[0m in [0;36mmakedirs[1;34m(name, mode, exist_ok)[0m
[0;32m    211[0m     [1;32mif[0m [0mhead[0m [1;32mand[0m [0mtail[0m [1;32mand[0m [1;32mnot[0m [0mpath[0m[1;33m.[0m[0mexists[0m[1;33m([0m[0mhead[0m[1;33m)[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    212[0m         [1;32mtry[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 213[1;33m             [0mmakedirs[0m[1;33m([0m[0mhead[0m[1;33m,[0m [0mexist_ok[0m[1;33m=[0m[0mexist_ok[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    214[0m         [1;32mexcept[0m [0mFileExistsError[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    215[0m             [1;31m# Defeats race condition when another thread created the path[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;32mD:\ProgramData\Anaconda3\lib\os.py[0m in [0;36mmakedirs[1;34m(name, mode, exist_ok)[0m
[0;32m    221[0m             [1;32mreturn[0m[1;33m[0m[1;33m[0m[0m
[0;32m    222[0m     [1;32mtry[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[1;32m--> 223[1;33m         [0mmkdir[0m[1;33m([0m[0mname[0m[1;33m,[0m [0mmode[0m[1;33m)[0m[1;33m[0m[1;33m[0m[0m
[0m[0;32m    224[0m     [1;32mexcept[0m [0mOSError[0m[1;33m:[0m[1;33m[0m[1;33m[0m[0m
[0;32m    225[0m         [1;31m# Cannot rely on checking for EEXIST, since the operating system[0m[1;33m[0m[1;33m[0m[1;33m[0m[0m

[1;31mPermissionError[0m: [WinError 5] 拒绝访问。: '../../data'
PermissionError: [WinError 5] 拒绝访问。: '../../data'

