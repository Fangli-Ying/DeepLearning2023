
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>第六章 图理论基础 （未完待续） &#8212; 深度学习</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/chpt6/graph';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="1. NLP模型简介 (Introduction to NLP Model)（未完待续）" href="../chpt5/Ch1-Introduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/dp.gif" class="logo__image only-light" alt="深度学习 - Home"/>
    <img src="../../_static/dp.gif" class="logo__image only-dark pst-js-only" alt="深度学习 - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    欢迎来到《深度学习原理及其应用》
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">深度学习基础</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chpt1/DeepLearning.html">第一章 深度学习基础</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">视觉基本任务</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chpt2/Ch1-Object-Detection.html">1. 目标检测简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt2/Ch2-EDA.html">2. 数据探索</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt2/Ch4-RetinaNet.html">4. RetinaNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt2/Ch5-Faster-R-CNN.html">5. Faster R-CNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt2/Ch5-References.html">6. 참고 문헌</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">深度生成模型</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chpt3/Ch1-Introduction.html">1. 生成对抗网络（GAN）简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt3/Ch2-EDA.html">2. EDA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt3/Ch3-GAN.html">3. GAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt3/Ch4-pix2pix.html">4. pix2pix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt3/Ch5-VAE.html">Variational Autoencoder（未完成）</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">序列模型</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chpt4/Ch1-Time-Series.html">1. Time Series 时间序列简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt4/Ch2-EDA.html">2. EDA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt4/Ch3-preprocessing.html">3. 数据预处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt4/Ch4-LSTM.html">4. LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chpt4/Ch5-CNN-LSTM.html">5. CNN-LSTM</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">自然语言处理</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chpt5/Ch1-Introduction.html">1. NLP模型简介 (Introduction to NLP Model)（未完待续）</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">图表示学习</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">第六章 图理论基础 （未完待续）</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/chapters/chpt6/graph.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>第六章 图理论基础 （未完待续）</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.1 图的背景：柯尼斯堡七桥问题</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.2 图的定义</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.3 图的性质</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neighbors">2.3.1 邻接节点（neighbors）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#degree">2.3.2 图的度 （degree）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#walk-path">2.3.3 行走（walk）和路径（path）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distance-diameter">2.3.4 距离（distance）、直径（diameter）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subgraph-connected-component-connected-graph">2.3.5 子图（subgraph）、连通分量（connected component）、连通图（connected graph）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-coefficient">2.3.6 聚类系数（Clustering Coefficient）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#closeness-centrality">2.3.7 接近中心度 (closeness centrality)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.4 图的连接表示</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adjacency-matrix">2.4.1 邻接矩阵 （Adjacency Matrix）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incidence-matrix">2.4.2 关联矩阵（Incidence Matrix）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-matrix">2.4.3 拉普拉斯矩阵（Laplacian Matrix）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.5 图的类型</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">2.5.1 图的拓扑结构</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">2.5.2 同质图和异质图</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bipartite-graph">2.5.3 二分图 （bipartite graph）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.6 参考资料</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>第六章 图理论基础 （未完待续）<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
<p>本章包含图的背景、图的定义、图的性质、图的连接表示、图的类型等，同时我们会学习使用 NetworkX 作为工具来学习和可视化基本的图。</p>
<p>首先，我们导入 NetworkX 工具包。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 导入 networkx 包</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
<p>关于 NetworkX 更多详细的使用，可以参考其官方文档：<a class="reference external" href="https://networkx.github.io/">https://networkx.github.io/</a></p>
<section id="id2">
<h2>2.1 图的背景：柯尼斯堡七桥问题<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p><strong>柯尼斯堡七桥问题</strong>（德语：Königsberger Brückenproblem；英语：Seven Bridges of Königsberg）是图论中的著名问题。这个问题是基于一个现实生活中的事例：当时东普鲁士柯尼斯堡（今日俄罗斯加里宁格勒），<strong>市区跨普列戈利亚河两岸</strong>，<strong>河中心有两个小岛</strong>。<strong>小岛与河的两岸有七条桥连接。在所有桥都只能走一遍的前提下，如何才能把这个地方所有的桥都走遍？</strong></p>
<p>莱昂哈德·<strong>欧拉</strong>在1735年提出，并没有方法能圆满解决这个问题，他更在第二年发表在论文《柯尼斯堡的七桥》中，证明符合条件的走法并不存在，也顺带提出和解决了一笔画问题。这篇论文在圣彼得堡科学院发表，成为图论史上第一篇重要文献。</p>
<p>欧拉把<strong>实际的抽象问题简化为平面上的点与线组合</strong>，<strong>每一座桥视为一条线</strong>，<strong>桥所连接的地区视为点</strong>。<strong>这样若从某点出发后最后再回到这点，则这一点的线数必须是偶数</strong>，这样的点称为偶顶点。相对的，连有奇数条线的点称为奇顶点。欧拉论述了，由于柯尼斯堡七桥问题中存在4个奇顶点，它无法实现符合题意的遍历。</p>
<p>柯尼斯堡七桥问题及其抽象化：</p>
<center>
    <img src="../../figures/02图理论基础/2_seven_bridge.PNG" width=600> 
    <br>
    <div>图2-1. 柯尼斯堡七桥问题及其抽象化</div>
</center>
<p>欧拉把问题的实质归于<strong>一笔画问题</strong>，即判断一个图是否能够遍历完所有的边而没有重复，而柯尼斯堡七桥问题则是一笔画问题的一个具体情境。欧拉最后给出任意一种河──桥图能否全部走一次的判定法则，从而解决了“一笔画问题”。对于一个给定的连通图，如果存在超过两个的奇顶点，那么满足要求的路线便不存在了，且有n个奇顶点的图至少需要 <span class="math notranslate nohighlight">\({\displaystyle \lceil {\frac {n}{2}}\rceil }\)</span> 笔画出。如果只有两个奇顶点，则可从其中任何一地出发完成一笔画。若所有点均为偶顶点，则从任何一点出发，所求的路线都能实现，他还说明了怎样快速找到所要求的路线。</p>
<p>不少数学家都尝试去解析这类事例。而这些解析，最后发展成为了数学中的<strong>图论</strong>。</p>
</section>
<section id="id3">
<h2>2.2 图的定义<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>一个<strong>图</strong>被记为 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span>。</p></li>
<li><p>其中 <span class="math notranslate nohighlight">\({V}=\{v_{1}, \ldots, v_{N}\}\)</span> 是数量为 <span class="math notranslate nohighlight">\(N=|{V}|\)</span> 的<strong>节点（node或vertex）的集合</strong>， <span class="math notranslate nohighlight">\({E}=\{e_{1}, \ldots, e_{M}\}\)</span> 是数量为 <span class="math notranslate nohighlight">\(M\)</span> 的<strong>边（edge或link）的集合</strong>。</p></li>
<li><p>图用节点表示实体（entities），用边表示实体间的关系（relations）。</p></li>
<li><p>假如一条边 <span class="math notranslate nohighlight">\(e\in{E}\)</span> 连接两个节点 <span class="math notranslate nohighlight">\(v_{1}\)</span> 和 <span class="math notranslate nohighlight">\(v_{2}\)</span>，那么这条边可以被表示为 <span class="math notranslate nohighlight">\(e=(v_{1}, v_{2})\)</span>。</p></li>
<li><p>节点和边的信息可以是<strong>类别型</strong>的（categorical），类别型数据的取值只能是哪一类别。一般称类别型的信息为<strong>标签（label）</strong>。</p></li>
<li><p>节点和边的信息可以是<strong>数值型</strong>的（numeric），数值型数据的取值范围为实数。一般称数值型的信息为<strong>属性（attribute）</strong>。</p></li>
<li><p>在图的计算任务中，我们认为，节点一定含有信息（至少含有节点的度的信息），边可能含有信息。</p></li>
</ul>
<p>下面，我们通过 NetworkX 创建一个简单的图。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 创建一个图</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="c1"># 添加图的节点</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="c1"># 添加图的边</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># 当添加的边对应的节点不存在的时候，会自动创建相应的节点</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="c1"># 绘制图</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
<center>
    <img src="../../figures/02图理论基础/2_NetworkX_Graph.png" width=400> 
    <br>
    <div>图2-2. NetworX 创建图</div>
</center>
<p>图根据它的边是否具有指向性可以分为：</p>
<ul class="simple">
<li><p><strong>有向图（directed graph or digraph）</strong>：有向图的边是具备指向性的。</p></li>
<li><p><strong>无向图（undirected graph）</strong>：无向图的边不具备指向性。</p></li>
</ul>
<center>
    <img src="../../figures/02图理论基础/2_digraph.PNG" width=500> 
    <br>
    <div>图2-3. 有向图和无向图</div>
</center>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 默认情况下，networkX 创建的是无向图</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">is_directed</span><span class="p">())</span>

<span class="c1"># 创建有向图</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">H</span><span class="o">.</span><span class="n">is_directed</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">False</span>
<span class="kc">True</span>
</pre></div>
</div>
<p>根据图的边上权重是否为 <span class="math notranslate nohighlight">\(1\)</span>，我们可以将它们分为：</p>
<ul class="simple">
<li><p>图的边上的权重为 <span class="math notranslate nohighlight">\(1\)</span> 时，它是一个无权图（unweighted graph）。</p></li>
<li><p>图的边上的权重不为 <span class="math notranslate nohighlight">\(1\)</span> 的时候，它是一个有权图（weighted graph）。我们记点 <span class="math notranslate nohighlight">\(v_i\)</span> 到 <span class="math notranslate nohighlight">\(v_j\)</span> 的权重为 <span class="math notranslate nohighlight">\(w_{ij}\)</span>.</p></li>
</ul>
<center>
    <img src="../../figures/02图理论基础/2_weighted_graph.PNG" width=500> 
    <br>
    <div>图2-4. 有权图和无权图</div>
</center>
</section>
<section id="id4">
<h2>2.3 图的性质<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>由于上面创建的图太小，为了方便计算图的性质，我们使用一个 NetworkX 中自带的图 The Karate Club Network（空手道俱乐部网络）进行学习。</p>
<p>空手道俱乐部网络描述了空手道俱乐部 34 名成员的社交网络，并记录了在俱乐部外互动的成员之间的链接。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 创建一个空手道俱乐部网络</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">karate_club_graph</span><span class="p">()</span>
<span class="c1"># G is an undirected graph</span>
<span class="nb">type</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="c1"># 可视化图</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">with_labels</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<center>
    <img src="../../figures/02图理论基础/2_karate_club.png" width=500> 
    <br>
    <div>图2-5. 空手道俱乐部图</div>
</center>
<section id="neighbors">
<h3>2.3.1 邻接节点（neighbors）<a class="headerlink" href="#neighbors" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>节点 <span class="math notranslate nohighlight">\(v_i\)</span> 的邻接节点</strong>是与节点 <span class="math notranslate nohighlight">\(v_i\)</span> 直接相连的节点，其被记为 <span class="math notranslate nohighlight">\({N(v_i)}\)</span>。</p></li>
<li><p>节点 <span class="math notranslate nohighlight">\(v_i \)</span>的 <span class="math notranslate nohighlight">\(k\)</span> 跳远的邻接节点（neighbors with <span class="math notranslate nohighlight">\(k\)</span>-hop）是到节点 <span class="math notranslate nohighlight">\(v_i\)</span> 要走 <span class="math notranslate nohighlight">\(k\)</span> 步的节点（一个节点的 <span class="math notranslate nohighlight">\(2\)</span> 跳远的邻接节点包含了自身）。</p></li>
</ul>
</section>
<section id="degree">
<h3>2.3.2 图的度 （degree）<a class="headerlink" href="#degree" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>节点 <span class="math notranslate nohighlight">\(v_i\)</span> 的度记为 <span class="math notranslate nohighlight">\(d(v_i)\)</span>，入度记为 <span class="math notranslate nohighlight">\(d_{in}(v_i)\)</span>，出度记为 <span class="math notranslate nohighlight">\(d_{out}(v_i)\)</span>。</p></li>
<li><p>对于<strong>有向有权图</strong>：节点 <span class="math notranslate nohighlight">\(v_i\)</span> 的出度（out degree）等于从 <span class="math notranslate nohighlight">\(v_i\)</span> 出发的边的权重之和；节点 <span class="math notranslate nohighlight">\(v_i\)</span> 的入度（in degree）等于从连向 <span class="math notranslate nohighlight">\(v_i\)</span> 的边的权重之和。</p></li>
<li><p><strong>无向图</strong>是有向图的特殊情况，节点的出度与入度相等。</p></li>
<li><p><strong>无权图</strong>是有权图的特殊情况，各边的权重为 <span class="math notranslate nohighlight">\(1\)</span>，那么节点 <span class="math notranslate nohighlight">\(v_i\)</span> 的出度（out degree）等于从 <span class="math notranslate nohighlight">\(v_i\)</span> 出发的边的数量，节点 <span class="math notranslate nohighlight">\(v_i\)</span> 的入度（in degree）等于从连向 <span class="math notranslate nohighlight">\(v_i\)</span> 的边的数量。</p></li>
<li><p><strong>平均度</strong>是一个表达网络整体性质重要的参数。对于无向图来说，平均度的计算为 <span class="math notranslate nohighlight">\(\bar{d}({G})=\frac{1}{N}\sum^{N}_{i=1}d_i=\frac{2M}{N}\)</span>。</p></li>
<li><p><strong>度分布 <span class="math notranslate nohighlight">\(P(d)\)</span></strong> 表示随机选择的节点的度为 <span class="math notranslate nohighlight">\(d\)</span> 的概率，平均度 <span class="math notranslate nohighlight">\(\bar{d}({G})=\sum_{d=0}^{\infty} dP(d)\)</span>。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 网络平均度的计算</span>
<span class="k">def</span> <span class="nf">average_degree</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">):</span>
    <span class="c1"># this function takes number of edges and number of nodes</span>
    <span class="c1"># returns the average node degree of the graph. </span>
    <span class="c1"># Round the result to nearest integer (for example 3.3 will be rounded to 3 and 3.7 will be rounded to 4)</span>
    <span class="n">avg_degree</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1">#########################################</span>
    <span class="n">avg_degree</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">num_edges</span><span class="o">/</span><span class="n">num_nodes</span>
    <span class="n">avg_degree</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">avg_degree</span><span class="p">))</span>
    <span class="c1">#########################################</span>
    <span class="k">return</span> <span class="n">avg_degree</span>

<span class="n">num_edges</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()</span>
<span class="n">avg_degree</span> <span class="o">=</span> <span class="n">average_degree</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average degree of karate club network is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_degree</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Average</span> <span class="n">degree</span> <span class="n">of</span> <span class="n">karate</span> <span class="n">club</span> <span class="n">network</span> <span class="ow">is</span> <span class="mi">5</span>
</pre></div>
</div>
</section>
<section id="walk-path">
<h3>2.3.3 行走（walk）和路径（path）<a class="headerlink" href="#walk-path" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(walk(v_1, v_2) = (v_1, e_6,e_5,e_4,e_1,v_2)\)</span>，这是一次“行走”，它是一次从节点 <span class="math notranslate nohighlight">\(v_1\)</span> 出发，依次经过边 <span class="math notranslate nohighlight">\(e_6,e_5,e_4,e_1\)</span>，最终到达节点 <span class="math notranslate nohighlight">\(v_2\)</span> 的“行走”。</p></li>
<li><p>下图所示为 <span class="math notranslate nohighlight">\(walk(v_1, v_2) = (v_1, e_6,e_5,e_4,e_1,v_2)\)</span>，其中红色数字标识了边的访问序号。</p></li>
<li><p>在“行走”中，节点是允许重复的。</p></li>
<li><p><strong>路径</strong>是节点不可重复的<strong>行走</strong>。</p></li>
</ul>
<center>
    <img src="../../figures/02图理论基础/2_walk.png" width=300> 
    <br>
    <div>图2-6. 行走</div>
</center>
</section>
<section id="distance-diameter">
<h3>2.3.4 距离（distance）、直径（diameter）<a class="headerlink" href="#distance-diameter" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>最短路径被定义为两个点之间的<strong>距离（distance）</strong>。<strong>最短路径（shortest path）</strong> <span class="math notranslate nohighlight">\(v_{s}, v_{t} \in {V}\)</span> 是图 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span> 上的一对节点，节点对 <span class="math notranslate nohighlight">\(v_{s}, v_{t} \in {V}\)</span> 之间所有路径的集合记为 <span class="math notranslate nohighlight">\(p_{st}\)</span>。节点对 <span class="math notranslate nohighlight">\(v_{s}, v_{t}\)</span> 之间的最短路径 <span class="math notranslate nohighlight">\(p_{st}^{sp}\)</span> 为 <span class="math notranslate nohighlight">\(p_{st}\)</span> 中长度最短的一条路径，其形式化定义为
$<span class="math notranslate nohighlight">\(p_{st}^{sp}= argmin_{p \in P_{st}}|p|\)</span><span class="math notranslate nohighlight">\(
其中， \)</span>p<span class="math notranslate nohighlight">\(表示  \)</span>p_{st}<span class="math notranslate nohighlight">\( 中的一条路径，\)</span>|p|<span class="math notranslate nohighlight">\(是路径\)</span>p$的长度。</p></li>
<li><p><strong>直径（diameter）</strong>：给定一个连通图 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span>，其直径为其所有节点对之间的<strong>最短路径的最大值</strong>，形式化定义为</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
diameter({G})=max_{v_{s}, v_{t} \in {V}} min_{p \in p_{s t}}|p|
\]</div>
</section>
<section id="subgraph-connected-component-connected-graph">
<h3>2.3.5 子图（subgraph）、连通分量（connected component）、连通图（connected graph）<a class="headerlink" href="#subgraph-connected-component-connected-graph" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>子图（subgraph）</strong>：有一图 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span> ，另有一图 <span class="math notranslate nohighlight">\({G}^{\prime}=\{{V}^{\prime}, {E}^{\prime}\}\)</span> ，其中 <span class="math notranslate nohighlight">\({V}^{\prime} \in {V}\)</span> ， <span class="math notranslate nohighlight">\({E}^{\prime} \in {E}\)</span> 并且 <span class="math notranslate nohighlight">\({V}^{\prime}\)</span> 不包含 <span class="math notranslate nohighlight">\({E}^{\prime}\)</span> 中未出现过的节点，那么 <span class="math notranslate nohighlight">\({G}^{\prime}\)</span> 是 <span class="math notranslate nohighlight">\({G}\)</span> 的子图。</p></li>
<li><p><strong>连通分量（connected component）</strong>：给定图 <span class="math notranslate nohighlight">\({G}^{\prime}=\{{V}^{\prime}, {E}^{\prime}\}\)</span> 是图 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span> 的子图。记属于图 <span class="math notranslate nohighlight">\({G}\)</span> 但不属于 <span class="math notranslate nohighlight">\({G}^{\prime}\)</span> 图的节点集合记为 <span class="math notranslate nohighlight">\({V} \setminus {V}^{\prime}\)</span> 。如果属于 <span class="math notranslate nohighlight">\({V}^{\prime}\)</span> 的任意节点对之间存在至少一条路径，但不存在一条边连接属于 <span class="math notranslate nohighlight">\({V}^{\prime}\)</span> 的节点与属于 <span class="math notranslate nohighlight">\({V} \setminus {V}^{\prime}\)</span> 的节点，那么图 <span class="math notranslate nohighlight">\({G}^{\prime}\)</span> 是图 <span class="math notranslate nohighlight">\({G}\)</span> 的连通分量。</p></li>
<li><p><strong>连通图（connected graph）</strong>：当一个图只包含一个连通分量，即其自身，那么该图是一个连通图。</p></li>
</ul>
</section>
<section id="clustering-coefficient">
<h3>2.3.6 聚类系数（Clustering Coefficient）<a class="headerlink" href="#clustering-coefficient" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>聚类系数表示给定节点的<strong>邻居彼此链接的程度</strong>。</p></li>
<li><p>节点 <span class="math notranslate nohighlight">\(i\)</span> 的邻域互连越紧密，其局部聚类系数越高。</p></li>
<li><p><span class="math notranslate nohighlight">\(C_i\)</span> 是节点的两个邻居相互链接的概率。</p></li>
<li><p>对于度数为 <span class="math notranslate nohighlight">\(d_i\)</span> 的节点 i，<strong>局部聚类系数</strong>定义为
$<span class="math notranslate nohighlight">\(C_i=\frac{E_i}{T_i}\)</span>$</p></li>
</ul>
<p>其中，<span class="math notranslate nohighlight">\(E_i\)</span> 表示节点 <span class="math notranslate nohighlight">\(i\)</span> 的邻居实际存在的边的数量，<span class="math notranslate nohighlight">\(T_i\)</span> 表示节点 <span class="math notranslate nohighlight">\(i\)</span> 的邻居可能（最多）存在的边的数量。</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(C_i = 0\)</span> 如果节点 i 的邻居都没有相互链接。</p></li>
<li><p><span class="math notranslate nohighlight">\(C_i = 1\)</span> 如果节点 i 的邻居形成一个全连接图，即它们都相互链接。</p></li>
<li><p><span class="math notranslate nohighlight">\(C_i = 0.5\)</span> 意味着一个节点的两个邻居有 <span class="math notranslate nohighlight">\(50\%\)</span> 的机会链接。</p></li>
<li><p><strong>网络的聚类系数</strong>即<strong>平均聚类系数</strong>：是所有节点的集聚系数的平均值为
$<span class="math notranslate nohighlight">\(C=\frac{1}{N}\sum_i C_i\)</span>$</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">average_clustering_coefficient</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
    <span class="c1"># this function that takes a nx.Graph</span>
    <span class="c1"># and returns the average clustering coefficient. </span>
    <span class="c1"># Round the result to 2 decimal places (for example 3.333 will be rounded to 3.33 and 3.7571 will be rounded to 3.76)</span>
    <span class="n">avg_cluster_coef</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1">#########################################</span>
    <span class="c1">## Note: </span>
    <span class="c1">## 1: Please use the appropriate NetworkX clustering function</span>
    <span class="n">avg_cluster_coef</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">average_clustering</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="n">avg_cluster_coef</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">avg_cluster_coef</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1">#########################################</span>
    <span class="k">return</span> <span class="n">avg_cluster_coef</span>

<span class="n">avg_cluster_coef</span> <span class="o">=</span> <span class="n">average_clustering_coefficient</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average clustering coefficient of karate club network is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_cluster_coef</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Average</span> <span class="n">clustering</span> <span class="n">coefficient</span> <span class="n">of</span> <span class="n">karate</span> <span class="n">club</span> <span class="n">network</span> <span class="ow">is</span> <span class="mf">0.57</span>
</pre></div>
</div>
</section>
<section id="closeness-centrality">
<h3>2.3.7 接近中心度 (closeness centrality)<a class="headerlink" href="#closeness-centrality" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>在连通图中，节点的<strong>接近中心性</strong>（或接近性）是网络中中心性的度量，计算为该节点与图中所有其他节点之间的最短路径长度之和的倒数。</p></li>
<li><p>节点越中心，它与所有其他节点越接近。</p></li>
<li><p>接近中心度的计算公式为
$<span class="math notranslate nohighlight">\(c(v) = \frac{1}{\sum_{u \neq v}\text{shortest path length between } u \text{ and } v}\)</span>$</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="c1"># the function that calculates closeness centrality </span>
    <span class="c1"># for a node in karate club network. G is the input karate club </span>
    <span class="c1"># network and node is the node id in the graph. Please round the </span>
    <span class="c1"># closeness centrality result to 2 decimal places.</span>

    <span class="n">closeness</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1">#########################################</span>
    <span class="c1"># Raw version following above equation</span>
    <span class="c1"># source: https://stackoverflow.com/questions/31764515/find-all-nodes-connected-to-n</span>
    <span class="n">path_length_total</span> <span class="o">=</span> <span class="mi">0</span> 
    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">single_source_shortest_path</span><span class="p">(</span><span class="n">G</span><span class="p">,</span><span class="n">node</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">path_length_total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>

    <span class="n">closeness</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">path_length_total</span>
    <span class="n">closeness</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">closeness</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">closeness</span>

<span class="n">node</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">closeness</span> <span class="o">=</span> <span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="n">node</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The karate club network has closeness centrality (raw) </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">closeness</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">karate</span> <span class="n">club</span> <span class="n">network</span> <span class="n">has</span> <span class="n">closeness</span> <span class="n">centrality</span> <span class="p">(</span><span class="n">raw</span><span class="p">)</span> <span class="mf">0.01</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Normalized version from NetworkX</span>
<span class="c1"># Notice that networkx closeness centrality returns the normalized </span>
<span class="c1"># closeness directly, which is different from the raw (unnormalized) </span>
<span class="c1"># one that we learned in the lecture.</span>
<span class="n">closeness</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The karate club network has closeness centrality (normalzied) </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">closeness</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">karate</span> <span class="n">club</span> <span class="n">network</span> <span class="n">has</span> <span class="n">closeness</span> <span class="n">centrality</span> <span class="p">(</span><span class="n">normalzied</span><span class="p">)</span> <span class="mf">0.38</span>
</pre></div>
</div>
</section>
</section>
<section id="id5">
<h2>2.4 图的连接表示<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>下面我们会介绍邻接矩阵、关联矩阵和拉普拉斯矩阵。一些文献会把他们归入图的性质中，但是因为它们是后续图神经网络中使用的重点，我们单独对它们进行更详细的讲解。</p>
<section id="adjacency-matrix">
<h3>2.4.1 邻接矩阵 （Adjacency Matrix）<a class="headerlink" href="#adjacency-matrix" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>给定一个图 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span>，其对应的<strong>邻接矩阵</strong>被记为 <span class="math notranslate nohighlight">\(\mathbf{A} \in\{0,1\}^{N \times N}\)</span>。</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{A_{i,j}}=1\)</span> 表示存在从节点 <span class="math notranslate nohighlight">\(v_i\)</span> 到 <span class="math notranslate nohighlight">\(v_j\)</span> 的边，<span class="math notranslate nohighlight">\(\mathbf{A}_{i, j}=0\)</span> 表示不存在从节点 <span class="math notranslate nohighlight">\(v_i\)</span> 到 <span class="math notranslate nohighlight">\(v_j\)</span> 的边。</p></li>
<li><p>在<strong>无向图</strong>中，从节点 <span class="math notranslate nohighlight">\(v_i\)</span> 到 <span class="math notranslate nohighlight">\(v_j\)</span> 的边存在，意味着从节点 <span class="math notranslate nohighlight">\(v_j\)</span> 到 <span class="math notranslate nohighlight">\(v_i\)</span> 的边也存在。因而<strong>无向图的邻接矩阵是对称的</strong>。</p></li>
<li><p>在<strong>无权图</strong>中，<strong>各条边的权重被认为是等价的</strong>，即认为<strong>各条边的权重为1</strong>。</p></li>
<li><p>对于<strong>有权图</strong>，其对应的邻接矩阵通常被记为 <span class="math notranslate nohighlight">\(\mathbf{W} \in \mathbb{R}^{N \times N}\)</span>，其中 <span class="math notranslate nohighlight">\(\mathbf{W_{i, j}}=w_{ij}\)</span> 表示从节 <span class="math notranslate nohighlight">\(v_i\)</span> 到 <span class="math notranslate nohighlight">\(v_j\)</span> 的边的权重。若边不存在时，边的权重为 <span class="math notranslate nohighlight">\(0\)</span> 。</p></li>
</ul>
<p>一个无向无权图的例子（左边为图，右边为图的邻接矩阵）：</p>
<center>
    <img src="../../figures/02图理论基础/2_adjacency_matrix.png" width=600> 
    <br>
    <div>图2-7. 无向图的邻接矩阵</div>
</center>
</section>
<section id="incidence-matrix">
<h3>2.4.2 关联矩阵（Incidence Matrix）<a class="headerlink" href="#incidence-matrix" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>给定一个图 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span>，其对应的<strong>关联矩阵</strong>被记为 <span class="math notranslate nohighlight">\(\mathbf{M} \in\{0,1\}^{N \times M}\)</span>。（抱歉这里我们用加粗的 <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> 表示关联矩阵，用不加粗的 <span class="math notranslate nohighlight">\(M\)</span> 表示边的个数）</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M_{i, j}}=1\)</span> 表示节点 <span class="math notranslate nohighlight">\(v_i\)</span> 和边 <span class="math notranslate nohighlight">\(e_j\)</span> 相连接，<span class="math notranslate nohighlight">\(\mathbf{M_{i, j}}=0\)</span> 表示节点 <span class="math notranslate nohighlight">\(v_i\)</span> 和边 <span class="math notranslate nohighlight">\(e_j\)</span> 不相连接。</p></li>
<li><p>与邻接矩阵不同，关联矩阵描述的是定点和边之间的关系。</p></li>
</ul>
<p>一个无向无权图的例子（左边为图，右边为图的关联矩阵）：</p>
<center>
    <img src="../../figures/02图理论基础/2_incidence_matrix.PNG" width=600> 
    <br>
    <div>图2-8. 无向图的关联矩阵</div>
</center>
</section>
<section id="laplacian-matrix">
<h3>2.4.3 拉普拉斯矩阵（Laplacian Matrix）<a class="headerlink" href="#laplacian-matrix" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>拉普拉斯矩阵（Laplacian Matrix）</strong>：（也叫做 admittance matrix, Kirchhoff matrix）给定一个图 <span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span>，其邻接矩阵为 <span class="math notranslate nohighlight">\(A\)</span>，其拉普拉斯矩阵 <span class="math notranslate nohighlight">\(L\)</span> 定义为
$<span class="math notranslate nohighlight">\(\mathbf{L=D-A}\)</span><span class="math notranslate nohighlight">\(
其中\)</span>\mathbf{D=diag(d(v_1), \cdots, d(v_N))}<span class="math notranslate nohighlight">\(是度矩阵。更具体地，我们记拉普拉斯矩阵中每一个元素为 \)</span>L_{ij}$，那么每一个元素可以被定义为</p></li>
</ul>
<center>
    <img src="../../figures/02图理论基础/2_Equation_1.png"> 
</center>
<p>它的每一行和列的加和为<span class="math notranslate nohighlight">\(0\)</span>。</p>
<center>
    <img src="../../figures/02图理论基础/2_laplacian_matrix.PNG" width=600> 
    <br>
    <div>图2-9. 拉普拉斯矩阵</div>
</center>
<ul class="simple">
<li><p><strong>对称归一化的拉普拉斯矩阵，Symmetric normalized Laplacian）</strong>：给定一个图<span class="math notranslate nohighlight">\({G}=\{{V}, {E}\}\)</span>，其邻接矩阵为<span class="math notranslate nohighlight">\(A\)</span>，其规范化（归一化）的拉普拉斯矩阵定义为</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbf{L=D^{-\frac{1}{2}}(D-A)D^{-\frac{1}{2}}=I-D^{-\frac{1}{2}}AD^{-\frac{1}{2}}}
\]</div>
</section>
</section>
<section id="id6">
<h2>2.5 图的类型<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>按照不同的划分规则，图可以被划分为很多不同的种类。在 2.2 节中，我们根据边是否具有指向性，区分得到了有向图和无向图。下面，我们会根据更多不同的属性来对图进行划分。</p>
<section id="id7">
<h3>2.5.1 图的拓扑结构<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>根据图的拓扑结构，规则网络（regular network）可以分为</p>
<ul class="simple">
<li><p>全连接网络（fully-connected network）（下图左）</p></li>
<li><p>环形网络（ring-shape network）（下图中）</p></li>
<li><p>星形网络（start-shape network）（下图右）</p></li>
</ul>
<center>
    <img src="../../figures/02图理论基础/2_network_topology_regular.PNG" width=500> 
    <br>
    <div>图2-10. 图的拓扑结构</div>
</center>
<p>根据一些其他的不同性质，常见的图模型还有随机图（random graph）、小世界图（small world graph）和无标度图模型（scale-free graph）。</p>
<center>
    <img src="../../figures/02图理论基础/2_network_topology_other.png" width=500> 
    <br>
    <div>图2-11. 常见的图模型</div>
</center>
</section>
<section id="id8">
<h3>2.5.2 同质图和异质图<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>深度学习中的同质图和异质图和原本图理论中的定义稍有不同，这里我们只给出在深度学习中更常见的定义。</p>
<ul class="simple">
<li><p><strong>同质图</strong>（Homogeneous Graph）：只有一种类型的节点和一种类型的边的图。</p></li>
<li><p><strong>异质图</strong>（Heterogeneous Graph）：存在多种类型的节点和多种类型的边的图。</p></li>
</ul>
<center>
    <img src="../../figures/02图理论基础/2_heterogeneous.png" width=500> 
    <br>
    <div>图2-12. 异质图</div>
</center>
</section>
<section id="bipartite-graph">
<h3>2.5.3 二分图 （bipartite graph）<a class="headerlink" href="#bipartite-graph" title="Link to this heading">#</a></h3>
<p>二分图或二部图（Bipartite Graphs）：节点分为两类，只有不同类的节点之间存在边。</p>
<center>
    <img src="../../figures/02图理论基础/2_bipartite_real.png" width=200> 
    <br>
    <div>图2-13. 二分图</div>
</center>
<p>更具体地，二分图是一个网络，其节点可以分为两个不相交的集合 <span class="math notranslate nohighlight">\(U\)</span> 和 <span class="math notranslate nohighlight">\(V\)</span>，使得每个链接将 <span class="math notranslate nohighlight">\(U\)</span> 节点连接到 <span class="math notranslate nohighlight">\(V\)</span> 节点。换句话说，如果我们将 <span class="math notranslate nohighlight">\(U\)</span> 节点着色为绿色，将 <span class="math notranslate nohighlight">\(V\)</span> 节点着色为紫色，那么每个链接必须连接不同颜色的节点。我们可以为每个二分网络生成两个投影。如果两个 <span class="math notranslate nohighlight">\(U\)</span> 节点链接到二分表示中的相同 <span class="math notranslate nohighlight">\(V\)</span> 节点，则第一个投影通过链接连接两个 <span class="math notranslate nohighlight">\(U\)</span> 节点。如果它们连接到相同的 <span class="math notranslate nohighlight">\(U\)</span> 节点，则第二个投影通过链接连接 <span class="math notranslate nohighlight">\(V\)</span> 节点。</p>
<center>
    <img src="../../figures/02图理论基础/2_bipartite_network_science.PNG" width=400> 
    <br>
    <div>图2-14. 二分图</div>
</center>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 创建一个二分图 Bipartite Graph</span>
<span class="kn">from</span> <span class="nn">networkx.algorithms</span> <span class="kn">import</span> <span class="n">bipartite</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="c1"># Add nodes with the node attribute &quot;bipartite&quot;</span>
<span class="n">B</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">bipartite</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">B</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">([</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">],</span> <span class="n">bipartite</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Add edges only between nodes of opposite node sets</span>
<span class="n">B</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)])</span>
</pre></div>
</div>
</section>
</section>
<section id="id9">
<h2>2.6 参考资料<a class="headerlink" href="#id9" title="Link to this heading">#</a></h2>
<p>[1] 包勇军、朱小坤、颜伟鹏、姚普，<a class="reference external" href="http://www.tup.tsinghua.edu.cn/Wap/tsxqy.aspx?id=09165201">图深度学习从理论到实践</a>，清华大学出版社，2022</p>
<p>[2] Albert-László Barabási, <a class="reference external" href="http://networksciencebook.com/chapter/2">Network Science</a></p>
<p>[3] Guanrong Chen, <a class="reference external" href="https://www.amazon.com/Fundamentals-Complex-Networks-Structures-Dynamics/dp/1118718119">Fundamentals of Complex Networks: Models, Structures and Dynamics</a></p>
<p>[4] Jure Leskovec, <a class="reference external" href="https://web.stanford.edu/class/cs224w/">Stanford University CS224W: Machine Learning with Graphs</a></p>
<p>[5] Yao Ma and Jiliang Tang, <a class="reference external" href="https://web.njit.edu/~ym329/dlg_book/">Deep Learning on Graphs</a>, 2021</p>
<p>[6] 马耀、汤继良，<a class="reference external" href="https://item.jd.com/13221338.html">图深度学习（Deep Learning on Graphs 中文版）</a></p>
<p>[7] Datawhale，<a class="reference external" href="https://github.com/datawhalechina/team-learning-nlp/tree/master/GNN/">图神经网络组队学习</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters\chpt6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../chpt5/Ch1-Introduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">1. NLP模型简介 (Introduction to NLP Model)（未完待续）</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.1 图的背景：柯尼斯堡七桥问题</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.2 图的定义</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.3 图的性质</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neighbors">2.3.1 邻接节点（neighbors）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#degree">2.3.2 图的度 （degree）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#walk-path">2.3.3 行走（walk）和路径（path）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distance-diameter">2.3.4 距离（distance）、直径（diameter）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subgraph-connected-component-connected-graph">2.3.5 子图（subgraph）、连通分量（connected component）、连通图（connected graph）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-coefficient">2.3.6 聚类系数（Clustering Coefficient）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#closeness-centrality">2.3.7 接近中心度 (closeness centrality)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.4 图的连接表示</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adjacency-matrix">2.4.1 邻接矩阵 （Adjacency Matrix）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incidence-matrix">2.4.2 关联矩阵（Incidence Matrix）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#laplacian-matrix">2.4.3 拉普拉斯矩阵（Laplacian Matrix）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.5 图的类型</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">2.5.1 图的拓扑结构</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">2.5.2 同质图和异质图</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bipartite-graph">2.5.3 二分图 （bipartite graph）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.6 参考资料</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://fangli-ying.github.io/">Dr. Fangli Ying</a>
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>